{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/componavt/neural_synset/blob/master/%20%20%20%20src/dataset/wikt_labels_loading_a_custom_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading a custom dataset"
      ],
      "metadata": {
        "id": "QYfY37MqO5dt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDFTPRp_kZDn"
      },
      "source": [
        "Source code: [Loading a custom dataset](https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/load_custom_dataset.ipynb#scrollTo=D2ekPOyykZDq), [video](https://www.youtube.com/watch?v=HyQgpJTkRdE).\n",
        "\n",
        "Video: [The pipeline function](https://www.youtube.com/watch?v=tiZFewofSLM)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ6SxVN7kZDp"
      },
      "source": [
        "Install the Transformers and Datasets libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qGhcXHDgkZDq",
        "outputId": "e6329bd0-59be-47c8-e002-1d544a717590",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.4.2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.1.99)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.20.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.18.0 dill-0.3.8 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "! pip install datasets transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "D2ekPOyykZDq",
        "outputId": "ca5d64fe-c3f4-408e-9ca5-b3c0c9a171c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-21 08:23:51--  https://github.com/componavt/neural_synset/raw/master/data/label_meaning.csv\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/componavt/neural_synset/master/data/label_meaning.csv [following]\n",
            "--2024-03-21 08:23:51--  https://raw.githubusercontent.com/componavt/neural_synset/master/data/label_meaning.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1227 (1.2K) [text/plain]\n",
            "Saving to: ‘label_meaning.csv’\n",
            "\n",
            "label_meaning.csv   100%[===================>]   1.20K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-21 08:23:52 (43.8 MB/s) - ‘label_meaning.csv’ saved [1227/1227]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/componavt/neural_synset/raw/master/data/label_meaning.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat label_meaning.csv"
      ],
      "metadata": {
        "id": "p12P46-URgjA",
        "outputId": "65482940-79b3-4c8a-cbe4-25c2d283dd6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"word\"|\"meaning\"|\"книжн.\"|\"ирон.\"|\"религ.\"|\"груб.\"\n",
            "подвизаться|осуществлять деятельность, работать, действовать в какой-нибудь области|1|1|0|0\n",
            "подвизаться|совершать подвиг в чём-либо, часто о ежедневном борении|0|0|1|0\n",
            "заткнуться|то же, что замолчать; перестать говорить, кричать, плакать; замолкнуть|0|0|0|1\n",
            "пустобрёх|тот, кто говорит много пустого и несерьёзного; болтун|0|0|0|1\n",
            "излаять|сильно изругать|0|0|0|1\n",
            "бизнес-дама|о предпринимательнице|0|1|0|0\n",
            "агнец божий|кроткий, робкий, безобидный человек|0|1|0|0\n",
            "всезнайка|человек, который считает себя знающим всё|0|1|0|0\n",
            "галантерейный|относящийся к галантерее|0|0|0|0\n",
            "галантерейный|чрезмерно любезный, вежливый до слащавости|0|1|0|0\n",
            "дитятя|дитя, ребёнок, чадо|0|1|0|0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aDxEoWmpkZDr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9950eb16-1c16-4694-c8dc-45991094072d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['word', 'meaning', 'книжн.', 'ирон.', 'религ.', 'груб.'],\n",
              "    num_rows: 11\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "#ds = load_dataset(\"csv\", data_files=\"label_meaning.csv\", sep=\"|\")\n",
        "ds = load_dataset(\"csv\", data_files=\"label_meaning.csv\", sep=\"|\", split='train')\n",
        "#ds[\"train\"]\n",
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "jkxsM9tFkZDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b36eaf2f-f5a3-4869-d8c8-358073f1e675"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['word', 'meaning', 'книжн.', 'ирон.', 'религ.', 'груб.'],\n",
              "        num_rows: 8\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['word', 'meaning', 'книжн.', 'ирон.', 'религ.', 'груб.'],\n",
              "        num_rows: 3\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "# 80% train, 20% test + validation\n",
        "datushka = ds.train_test_split(test_size=0.2, shuffle=True)\n",
        "datushka\n",
        "#datushka[\"train\"]\n",
        "#datushka[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(datushka[\"train\"][0])\n",
        "print(len(list(datushka[\"train\"])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ68f-qjYphI",
        "outputId": "28ea4853-98b1-45e5-aed3-b3c64563f1a5"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline: zero shot classification with labels: education, business and politics"
      ],
      "metadata": {
        "id": "uoI-t2YpPFd7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When more than one label is passed, we assume that there is only one true label and that the others are false so that the output probabilities add up to 1. This can be changed by passing `multi_class=True`:\n",
        "nlp(sequence_to_classify, candidate_labels, multi_class=True)\n",
        "\n",
        "Source: huggingface/transformers/[Zero shot classification pipeline #5760 ](https://github.com/huggingface/transformers/pull/5760)."
      ],
      "metadata": {
        "id": "zCN6OuQ1jo5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "model_id = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "pipe = pipeline(\"zero-shot-classification\", model=model_id)"
      ],
      "metadata": {
        "id": "rdusFXDDhN1m"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def meaning_iterator():\n",
        "    for i in range(0, len(datushka[\"train\"]), 1):\n",
        "        yield datushka[\"train\"][i][\"meaning\"]\n",
        "\n",
        "#print(len(datushka[\"train\"]))\n",
        "#datushka[\"train\"][0][\"meaning\"]\n",
        "#nlp(datushka[\"train\"][0][\"meaning\"], [\"positive\", \"negative\"], multi_label=True)\n",
        "###pipe(meaning_iterator(), [\"positive\", \"negative\"], multi_label=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9W53vwBJOjP",
        "outputId": "4b5875ca-4ac5-46bb-be2d-4cd0323bbce5"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#sequence_to_classify = \"тот, кто говорит много пустого и несерьёзного; болтун\"\n",
        "candidate_labels = [\"книжн.\", \"ирон.\", \"религ.\", \"груб.\"]\n",
        "#pipe(sequence_to_classify, candidate_labels, multi_label=True)\n",
        "\n",
        "#pipe(meaning_iterator(), candidate_labels, multi_label=True)\n",
        "pipe(datushka[\"train\"][0][\"meaning\"], candidate_labels, multi_label=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5wjiZz2mHOz",
        "outputId": "3b173cec-d4ee-4ff7-8471-7e65daaf8fc1"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'тот, кто говорит много пустого и несерьёзного; болтун',\n",
              " 'labels': ['груб.', 'ирон.', 'книжн.', 'религ.'],\n",
              " 'scores': [0.9954854249954224,\n",
              "  0.9225433468818665,\n",
              "  0.21135631203651428,\n",
              "  0.18404583632946014]}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}