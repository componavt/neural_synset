{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/componavt/neural_synset/blob/master/src/dataset/wikt_labels_tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading labels with definitions"
      ],
      "metadata": {
        "id": "QYfY37MqO5dt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDFTPRp_kZDn"
      },
      "source": [
        "Source code: [Loading a custom dataset](https://colab.research.google.com/github/huggingface/notebooks/blob/master/course/videos/load_custom_dataset.ipynb#scrollTo=D2ekPOyykZDq), [video](https://www.youtube.com/watch?v=HyQgpJTkRdE).\n",
        "\n",
        "Video: [The pipeline function](https://www.youtube.com/watch?v=tiZFewofSLM)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ6SxVN7kZDp"
      },
      "source": [
        "Install the Transformers and Datasets libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGhcXHDgkZDq"
      },
      "outputs": [],
      "source": [
        "! pip install -U accelerate\n",
        "! pip install -U transformers\n",
        "\n",
        "! pip install datasets transformers[sentencepiece]\n",
        "! pip install torch               # required by TrainingArguments\n",
        "! pip install transformers[torch] # required by TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2ekPOyykZDq"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/componavt/neural_synset/raw/master/data/label_meaning.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat label_meaning.csv"
      ],
      "metadata": {
        "id": "p12P46-URgjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDxEoWmpkZDr"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"csv\", data_files=\"label_meaning.csv\", sep=\"|\")\n",
        "#ds = load_dataset(\"csv\", data_files=\"label_meaning.csv\", sep=\"|\", split='train')\n",
        "#ds[\"train\"]\n",
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jkxsM9tFkZDu"
      },
      "outputs": [],
      "source": [
        "# 80% train, 20% test + validation\n",
        "#da = ds.train_test_split(test_size=0.2, shuffle=True)\n",
        "#da\n",
        "#datushka[\"train\"]\n",
        "#datushka[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(datushka[\"train\"][0])\n",
        "#print(len(list(datushka[\"train\"])))"
      ],
      "metadata": {
        "id": "pZ68f-qjYphI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline: zero shot classification with labels"
      ],
      "metadata": {
        "id": "uoI-t2YpPFd7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When more than one label is passed, we assume that there is only one true label and that the others are false so that the output probabilities add up to 1. This can be changed by passing `multi_class=True`:\n",
        "nlp(sequence_to_classify, candidate_labels, multi_class=True)\n",
        "\n",
        "Source: huggingface/transformers/[Zero shot classification pipeline #5760 ](https://github.com/huggingface/transformers/pull/5760)."
      ],
      "metadata": {
        "id": "zCN6OuQ1jo5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "model_name = \"MoritzLaurer/mDeBERTa-v3-base-mnli-xnli\"\n",
        "pipe = pipeline(\"zero-shot-classification\", model=model_name)"
      ],
      "metadata": {
        "id": "rdusFXDDhN1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def meaning_iterator():\n",
        "#    for i in range(0, len(da[\"train\"]), 1):\n",
        "#        yield da[\"train\"][i][\"meaning\"]\n",
        "\n",
        "#print(len(datushka[\"train\"]))\n",
        "#datushka[\"train\"][0][\"meaning\"]\n",
        "#nlp(datushka[\"train\"][0][\"meaning\"], [\"positive\", \"negative\"], multi_label=True)\n",
        "###pipe(meaning_iterator(), [\"positive\", \"negative\"], multi_label=True)"
      ],
      "metadata": {
        "id": "T9W53vwBJOjP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sequence_to_classify = \"тот, кто говорит много пустого и несерьёзного; болтун\"\n",
        "candidate_labels = [\"книжн.\", \"ирон.\", \"религ.\", \"груб.\"]\n",
        "#pipe(sequence_to_classify, candidate_labels, multi_label=True)\n",
        "\n",
        "#pipe(meaning_iterator(), candidate_labels, multi_label=True)\n",
        "#pipe(da[\"train\"][0][\"meaning\"], candidate_labels, multi_label=True)"
      ],
      "metadata": {
        "id": "Y5wjiZz2mHOz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AutoTokenizer and PyTorch optimized training loop\n",
        "From [quicktour.ipynb#AutoTokenizer](https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/quicktour.ipynb#scrollTo=c-mB_1hXw57y&line=1&uniqifier=1)"
      ],
      "metadata": {
        "id": "H_lPKhRJ1T49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup hyperparameters (learning rate, batch size, and the number of epochs to train for)\n",
        "from transformers import TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./pt_training\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=2,\n",
        "    )"
      ],
      "metadata": {
        "id": "zLrOxl5ABhgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fd9pj1zd4ziV"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#encoding = tokenizer( da[\"train\"][0][\"meaning\"] )\n",
        "#print(encoding)"
      ],
      "metadata": {
        "id": "SwziPWJf4-ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_dataset(dataset):\n",
        "  return tokenizer(dataset[\"meaning\"])"
      ],
      "metadata": {
        "id": "L4sWD7ui631j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#da[\"train\"]\n",
        "ds"
      ],
      "metadata": {
        "id": "wBWt_Wft-1SG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset = ds[\"train\"].map(tokenize_dataset, batched=True)\n",
        "dataset = ds.map(tokenize_dataset, batched=True)\n",
        "dataset"
      ],
      "metadata": {
        "id": "SGRkEGT2_ZNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a batch of examples from dataset\n",
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "data_collator"
      ],
      "metadata": {
        "id": "mE7Lmm9yAWLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 80% train, 20% test + validation\n",
        "dataset = dataset['train'].train_test_split(test_size=0.2, shuffle=True)\n",
        "dataset"
      ],
      "metadata": {
        "id": "X5fFPfUMJRy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gather all these classes in Trainer:\n",
        "from transformers import Trainer\n",
        "trainer = Trainer(\n",
        "    model=pt_model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    eval_dataset=dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")  # doctest: +SKIP"
      ],
      "metadata": {
        "id": "z83EmcCuAqop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n",
        "\n",
        "#see https://discuss.huggingface.co/t/the-model-did-not-return-a-loss-from-the-inputs-only-the-following-keys-logits-for-reference-the-inputs-it-received-are-input-values/25420"
      ],
      "metadata": {
        "id": "G2UZzJOWgTgu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}